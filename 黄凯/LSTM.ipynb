{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入评论数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('comments.csv')\n",
    "data = pd.read_csv('../Emotional-analysis-of-curriculum-review/黄忠财/newtest.csv')\n",
    "data = data[:11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data['comment'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = [list(jieba.cut(doc)) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 统计单词数<br>\n",
    "2. 构建word2index字典（留出0位作为padding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocb = set([word for words in words_list for word in words])\n",
    "word_to_idx = {word: (i+1) for i, word in enumerate(vocb)}\n",
    "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments_Bylist = []\n",
    "for doc in docs:\n",
    "    sentence = ''\n",
    "    sentence_list = []\n",
    "    for word in list(jieba.cut(doc)):\n",
    "        if sentence == '' and sentence_list is None:\n",
    "            sentence += word\n",
    "            sentence_list.append(word)\n",
    "        else:\n",
    "            sentence += (' ' + word)\n",
    "            sentence_list.append(word)\n",
    "    comments.append(sentence)\n",
    "    comments_Bylist.append(sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计分词后词频，并根据直方图确定合适的输入长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 494\n",
      "min: 2\n"
     ]
    }
   ],
   "source": [
    "comments_length = []\n",
    "for comment in comments_Bylist:\n",
    "    comments_length.append(len(comment))\n",
    "print('max:',max(comments_length))\n",
    "print('min:',min(comments_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.514e+03, 2.200e+03, 2.220e+03, 9.720e+02, 9.910e+02, 4.980e+02,\n",
       "        5.570e+02, 2.480e+02, 3.190e+02, 1.560e+02, 2.160e+02, 1.120e+02,\n",
       "        9.200e+01, 1.030e+02, 6.100e+01, 7.300e+01, 5.400e+01, 7.000e+01,\n",
       "        3.300e+01, 5.500e+01, 2.700e+01, 3.500e+01, 2.400e+01, 3.000e+01,\n",
       "        1.600e+01, 2.200e+01, 2.500e+01, 1.300e+01, 2.100e+01, 1.500e+01,\n",
       "        1.600e+01, 1.400e+01, 1.100e+01, 9.000e+00, 1.000e+01, 7.000e+00,\n",
       "        1.000e+01, 9.000e+00, 6.000e+00, 7.000e+00, 6.000e+00, 8.000e+00,\n",
       "        5.000e+00, 8.000e+00, 2.000e+00, 9.000e+00, 3.000e+00, 6.000e+00,\n",
       "        3.000e+00, 6.000e+00, 4.000e+00, 0.000e+00, 2.000e+00, 4.000e+00,\n",
       "        6.000e+00, 1.000e+00, 0.000e+00, 3.000e+00, 2.000e+00, 5.000e+00,\n",
       "        4.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 2.000e+00, 2.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 3.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([  2.  ,   4.46,   6.92,   9.38,  11.84,  14.3 ,  16.76,  19.22,\n",
       "         21.68,  24.14,  26.6 ,  29.06,  31.52,  33.98,  36.44,  38.9 ,\n",
       "         41.36,  43.82,  46.28,  48.74,  51.2 ,  53.66,  56.12,  58.58,\n",
       "         61.04,  63.5 ,  65.96,  68.42,  70.88,  73.34,  75.8 ,  78.26,\n",
       "         80.72,  83.18,  85.64,  88.1 ,  90.56,  93.02,  95.48,  97.94,\n",
       "        100.4 , 102.86, 105.32, 107.78, 110.24, 112.7 , 115.16, 117.62,\n",
       "        120.08, 122.54, 125.  , 127.46, 129.92, 132.38, 134.84, 137.3 ,\n",
       "        139.76, 142.22, 144.68, 147.14, 149.6 , 152.06, 154.52, 156.98,\n",
       "        159.44, 161.9 , 164.36, 166.82, 169.28, 171.74, 174.2 , 176.66,\n",
       "        179.12, 181.58, 184.04, 186.5 , 188.96, 191.42, 193.88, 196.34,\n",
       "        198.8 , 201.26, 203.72, 206.18, 208.64, 211.1 , 213.56, 216.02,\n",
       "        218.48, 220.94, 223.4 , 225.86, 228.32, 230.78, 233.24, 235.7 ,\n",
       "        238.16, 240.62, 243.08, 245.54, 248.  , 250.46, 252.92, 255.38,\n",
       "        257.84, 260.3 , 262.76, 265.22, 267.68, 270.14, 272.6 , 275.06,\n",
       "        277.52, 279.98, 282.44, 284.9 , 287.36, 289.82, 292.28, 294.74,\n",
       "        297.2 , 299.66, 302.12, 304.58, 307.04, 309.5 , 311.96, 314.42,\n",
       "        316.88, 319.34, 321.8 , 324.26, 326.72, 329.18, 331.64, 334.1 ,\n",
       "        336.56, 339.02, 341.48, 343.94, 346.4 , 348.86, 351.32, 353.78,\n",
       "        356.24, 358.7 , 361.16, 363.62, 366.08, 368.54, 371.  , 373.46,\n",
       "        375.92, 378.38, 380.84, 383.3 , 385.76, 388.22, 390.68, 393.14,\n",
       "        395.6 , 398.06, 400.52, 402.98, 405.44, 407.9 , 410.36, 412.82,\n",
       "        415.28, 417.74, 420.2 , 422.66, 425.12, 427.58, 430.04, 432.5 ,\n",
       "        434.96, 437.42, 439.88, 442.34, 444.8 , 447.26, 449.72, 452.18,\n",
       "        454.64, 457.1 , 459.56, 462.02, 464.48, 466.94, 469.4 , 471.86,\n",
       "        474.32, 476.78, 479.24, 481.7 , 484.16, 486.62, 489.08, 491.54,\n",
       "        494.  ]),\n",
       " <BarContainer object of 200 artists>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(comments_length,bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word->index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_ints = []\n",
    "\n",
    "\n",
    "for comment in comments_Bylist:\n",
    "    item_ints = []\n",
    "    for item in comment:\n",
    "        #print(item)\n",
    "        if item == '\\n' or item == ' ':\n",
    "            continue\n",
    "        item_ints.append(word_to_idx[str(item).replace(' ','')])\n",
    "    comments_ints.append(item_ints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding\n",
    "1. 根据直方图确定输入长度为12<br>\n",
    "2. 不足12的comment前端用0填充；超过12的comment截取前12个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1314   246  1488  6505  2688  6442  1444  8534  1050  2226]\n",
      " [ 6252   246  1062  1488  6505  7016  3474  8566  2438   246]\n",
      " [    0     0     0     0     0     0     0  7907  1444  7907]\n",
      " [ 6520  2383 10718  8600  2436  7586  7841   410  1444  5886]\n",
      " [    0     0     0     0     0     0     0     0     0  2901]\n",
      " [    0     0     0     0     0     0     0     0     0  9711]\n",
      " [    0     0     0     0     0     0     0     0  2056  2056]\n",
      " [ 9894  8802   596  5005  5483  3786  1444  5129  9153  4193]\n",
      " [    0     0     0     0     0     0     0     0  8585  1444]\n",
      " [    0     0     0     0     0     0     0     0  9899  5347]\n",
      " [ 1155  1062  2848   991  4653  4206 10248  1062  9122  8050]\n",
      " [    0     0     0     0     0     0     0  8802  9151   246]\n",
      " [    0     0     0     0     0     0  8820  2056  1444  4900]\n",
      " [    0     0     0     0     0     0  5193   564 10658  7842]\n",
      " [10108  7215  1155  4548  7015  7674  1251  5123  7892   246]\n",
      " [ 7322  7164  1444  7674  4687  4731  3129  1444  7170  3018]\n",
      " [ 5086  2134  7311  8050  9232  5123  9899  1444  6188   356]\n",
      " [    0     0  7674   169  3947  9078  1444  6505  6947  6779]\n",
      " [ 8534   589  4548  3466  8872  1444  9774  3466  9153  5424]\n",
      " [    0     0     0     0     0     0     0  8895  7463  7463]\n",
      " [ 8962  7381  5984  7568  7943  1444  5428  4451  5974  9834]\n",
      " [  963   347  7586  3180  1444  6505  1818   100  1444  6413]\n",
      " [    0     0  5129  5723  9834 10490  1056  7586   628  1444]\n",
      " [    0  9252  6793  4900  7563  1444  5123  7563 10876  3892]\n",
      " [ 2913  7571  2218   246  1444  7170  9330   246  6893  5347]\n",
      " [ 7437  7841    83  1444  8531  5974  7586  6009  1444  1000]\n",
      " [  937  8292  8839  7586  7563  1444  1562  5355  5325  7674]\n",
      " [    0     0     0     0     0     0     0     0  7674  2197]\n",
      " [    0     0     0  3466  4196  9151  9887  7674  1444  9198]\n",
      " [    0     0     0     0     0  2769  9151  9834  1757 10876]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    " \n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = reviews_ints[i][:seq_length]\n",
    "    \n",
    "    return features\n",
    " \n",
    " \n",
    " \n",
    "# Test your implementation!\n",
    " \n",
    "seq_length = 12\n",
    " \n",
    "features = pad_features(comments_ints, seq_length=seq_length)\n",
    " \n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(comments_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    " \n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(8800, 12) \n",
      "Validation set: \t(1100, 12) \n",
      "Test set: \t\t(1100, 12)\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = np.array(data['sentiment'].to_list())\n",
    "\n",
    "split_frac = 0.8\n",
    " \n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    " \n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    " \n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    " \n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建DataLoader，设置batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 12])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  7488,  7164,  1444,  8566,  1500,  7501,  9252,\n",
      "          6037,  4193],\n",
      "        [ 6285,  5347,  3018,  1444,  4973,  4900,  5889,  1444,  6505,  6943,\n",
      "          6779,   380],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,  9330,  2480,\n",
      "          1851,  1074],\n",
      "        [    0,     0,     0,     0,  7586,  3859,  2145,  3088,  5972,  5489,\n",
      "          7257,  7257],\n",
      "        [ 8050,    75,  6505,  2770,  4548, 10715,  6543,  3708,  9651,  9460,\n",
      "          4548,  5882],\n",
      "        [ 2848,  2436,  9754,   601,  9747,  5993,  2721,   246,  5975,  1444,\n",
      "          5611,  7674],\n",
      "        [    0,     0,  9330,  6063,  1444,  1314,   246,  9711,  1444,  7674,\n",
      "          1699,  3786],\n",
      "        [    0,  8050,  7015,  5563,  1444,  6884,  2743,  6770,  9030,  8050,\n",
      "          8292,  6101],\n",
      "        [  894,  9198,  7674,  2118,  5504,  1444,  3067,  5123,  7568,  6543,\n",
      "          7185,  4193],\n",
      "        [ 8382,  4948,   246,  2775,  8424,  1258,  6413,  1044,   328,  1085,\n",
      "          3116,  9527],\n",
      "        [ 2913,   219,  1444,  6939,  7240,  7322,   338,  8909,  1444,  6442,\n",
      "          4548,  7586],\n",
      "        [    0,     0,     0,     0,     0,     0,  9330,   169, 10922,  1444,\n",
      "          7322,  7164],\n",
      "        [    0,     0,     0,     0,     0,  6037,  7550,  1444,  3311,  6505,\n",
      "          2781,  7568],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  8769,  7164,  1444,\n",
      "           107,  1155],\n",
      "        [ 2717,  9834,  3808,   246,  4973,  1444,   798,  3808,  1647,  9984,\n",
      "         10655,   246],\n",
      "        [    0,  1314,   246,  7015,  5610,  1466,  1444,  5266,  4215,  2848,\n",
      "          7240,  1085],\n",
      "        [ 2913,  1314,   246,  5483,  7322, 10556,  7194,  1444,  5428,  8384,\n",
      "           246,  7299],\n",
      "        [    0,     0,     0,     0,     0,  7674,  5347,  2545,  1444,  9330,\n",
      "          7586,  5962],\n",
      "        [10421,  9385,  6278,  9122,  7322,  2347,   246,  7549,  1444,  5886,\n",
      "          6779,  4721],\n",
      "        [    0,  5347,  3286, 10125,  9834,  7232,  1444,  6668, 10658,  3008,\n",
      "          9265,  7463],\n",
      "        [ 4399,  5483,  7781,  9834,  1155,  1444, 10421,  2848, 10421,  6779,\n",
      "          4548,  9122],\n",
      "        [    0,     0,     0,     0,     0,  9330,  9043,  4374,  1444,  2848,\n",
      "          3873,  1155],\n",
      "        [    0,     0,     0,     0,     0,     0,  4512,  1870,   395,  6505,\n",
      "          4580,  4142],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,  4919,  9252,\n",
      "          1444, 10730],\n",
      "        [ 9330,   246,  1580,  5723,  5354,  7322,  4841,  1444,  6010,  7240,\n",
      "          7322,   216],\n",
      "        [ 9330,  2366,  1444,  7674,  8962,  9834,  5972,  7857,  5972,   192,\n",
      "          3859,  8185],\n",
      "        [    0,     0,     0,     0,  1169,  4550,  1062,  5193,   690, 10655,\n",
      "          1000,  6873],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,  1724,\n",
      "          1724,  1724],\n",
      "        [ 9330,  6939,  9069,  1949,  1444,  9189,  1969,  7578,  1444,  6171,\n",
      "           169,  1444],\n",
      "        [    0,     0,     0,     0,     0,     0,  5347,   871, 10326,   246,\n",
      "          9899,  6258],\n",
      "        [    0,     0,     0,     0,     0,     0,   283,  8725,  7041,  6258,\n",
      "          4844,  2127],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     1,  9330,  1444,\n",
      "           107,  2922],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   778,\n",
      "          8221,  9834],\n",
      "        [    0,     0,  5316, 10414,   601,  9834,  1155,  5993,  5030,   246,\n",
      "          7320,  5249],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,  2717,  9834,\n",
      "          9259,  2264],\n",
      "        [    0,     0,     0,     0,     0,  1724,  7463,  7463,  7463,  7463,\n",
      "          7463,  7463],\n",
      "        [ 4452,  5611, 10458,  5483,  1085,    41,  2848,  6525,  7225,  4193,\n",
      "          5316,  5025],\n",
      "        [ 5483,  8377,  1444,  8377,  1444,  7069,  5242,  5483,  2302,  1444,\n",
      "          2848,  9550],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  4503,   246,  3105,\n",
      "          1444,  4503],\n",
      "        [    0,     0,     0,     0,     0,     0, 10388,  7015,  7164,  1286,\n",
      "          7185,  7463],\n",
      "        [    0,  6652,  7674,  1444,  6010,  7488,  6283,  1444,  5123, 10248,\n",
      "           669,  5979],\n",
      "        [    0,     0,     0,  3723,  4538,  1444,  9596,  4128,  1444,  9053,\n",
      "          4128,  7463],\n",
      "        [ 7488,  1073,   246,  2596,  7674,  1444,  2848,  6520,  2436,  4653,\n",
      "          2582,  1444],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,  7907,\n",
      "          7907,  7907],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0, 10248,\n",
      "          7907,  7853],\n",
      "        [ 7674,   169,  4820,  1930,  1444,  7322,  8139,  9252,  5984,  8566,\n",
      "          8962,  1444],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,    75,\n",
      "          9887,   393],\n",
      "        [ 6520,  4538,  8883,  5504,  1444,  2662,  6753,  7164,  9550,  1444,\n",
      "          3859, 10421],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  9654,   137,  1444,\n",
      "          8050,  7496],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  1224,  1697,  4548,\n",
      "          5123,  4844]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    " \n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    " \n",
    "# dataloaders\n",
    "batch_size = 50\n",
    " \n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    " \n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    " \n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    " \n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, bidirectional=True, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    " \n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_size)\n",
    "          \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    " \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    " \n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "#         if bidirectional:\n",
    "#           lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim*2)\n",
    "#         else:\n",
    "#           lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "       \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "            number = 2\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers*number, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers*number, batch_size, self.hidden_dim).zero_().cuda()\n",
    "                     )\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers*number, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers*number, batch_size, self.hidden_dim).zero_()\n",
    "                     )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(10944, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "#vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "vocab_size = len(vocb)+1\n",
    "output_size = 1\n",
    "embedding_dim = 200\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "bidirectional = True  #这里为True，为双向LSTM\n",
    " \n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, bidirectional)\n",
    " \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.366501... Val Loss: 0.388199\n",
      "Epoch: 2/4... Step: 100... Loss: 0.154077... Val Loss: 0.336135\n",
      "Epoch: 3/4... Step: 100... Loss: 0.121731... Val Loss: 0.308698\n",
      "Epoch: 4/4... Step: 100... Loss: 0.236403... Val Loss: 0.356355\n"
     ]
    }
   ],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    counter = 0\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(counter)\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.364\n",
      "Test accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    " \n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    " \n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    " \n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    " \n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    " \n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    " \n",
    " \n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    " \n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review2list(content):\n",
    "    words_list = list(jieba.cut(content))\n",
    "    #print(words_list)\n",
    "    words_ints = []\n",
    "    for item in words_list:\n",
    "        try:\n",
    "            words_ints.append(word_to_idx[item])\n",
    "        except:\n",
    "            words_ints.append(0)\n",
    "    return [words_ints]#size(0)=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4183, 7240, 8570, 4989, 7463, 4844, 9330, 1175, 2145, 3088, 2848, 7240, 1085]]\n"
     ]
    }
   ],
   "source": [
    "review = '这也叫网课！？老师全程照着书念我也会'\n",
    "review_ints = review2list(review)\n",
    "print(review_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4183 7240 8570 4989 7463 4844 9330 1175 2145 3088 2848 7240]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 12\n",
    "features = pad_features(review_ints,seq_length)\n",
    "feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=12):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = review2list(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.002144\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "seq_length=12 # good to use the length that was trained on\n",
    "#review = '这也叫网课！？老师全程照着书念我也会'\n",
    "#review = '这也叫网课！？'\n",
    "review = '念PPT辛苦了 老师'\n",
    "predict(net, review, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
